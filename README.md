#cjc101-99
### **Transformer：生成式 AI 的核心架構**

現代生成式 AI 主要基於 **Transformer 網路**，這是一種由 Google 在 2017 年提出的**深度學習架構**，最著名的論文是： 📜 **《Attention Is All You Need》**（「注意力機制就是全部」）

Transformer 架構讓 AI 模型：

- **透過注意力機制（Attention Mechanism）** 有效地理解與生成語言。
- **能夠並行運算**，比 RNN（遞歸神經網絡）快得多。
- **可擴展性強**，支持超大規模訓練（如 GPT-4）。

目前最著名的生成式 AI 模型，如：

- **ChatGPT（GPT 系列）**
- **BERT（Google 搜索模型）**
- **T5、LLaMA、PaLM**
- **DALL·E、Stable Diffusion（圖像生成）**
- **Whisper（語音識別）**

這些模型的核心都基於 **Transformer 架構**。
